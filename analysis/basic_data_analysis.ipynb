{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic PUMS Analysis with SmartNoise\n",
    "\n",
    "This notebook will be a brief tutorial on doing data analysis within the SmartNoise system.\n",
    "\n",
    "We will start out by setting up our environment -- loading the necessary libraries and establishing the very basic things we need to know before loading our data (the file path and variable names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import opendp.smartnoise.core as sn\n",
    "\n",
    "# establish data information\n",
    "data_path = os.path.join('.', 'data', 'PUMS_california_demographics_1000', 'data.csv')\n",
    "var_names = [\"age\", \"sex\", \"educ\", \"race\", \"income\", \"married\", \"pid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties\n",
    "\n",
    "The core SmartNoise library is made up of two key pieces; the runtime and the validator. The runtime is made up of low-level algorithms and operations. The validator contains logic for combining runtime elements into more complex operations, as well as methods for determining whether or not a computation is differentially private. If an analysis plan is deemed to produce data that are not differentially private, the validator will not allow this analysis to run. Importantly, this is done independent of the underlying data.\n",
    "\n",
    "Whether or not a set of computations produces differentially private data relies on a set of properties of the data. These properties can be statically determined (without touching the actual data) and can be updated at each step of the analysis. One pair of common properties is `lower/upper`. For a differentially private mean, for example, the validator requires the input data to have defined lower and upper bounds. An analyst can ensure that `lower/upper` are set with the `clamp` component, which clamps data to a given range.  \n",
    "\n",
    "Let's say that we have access to the PUMS codebook, and thus know some basic information about the possible values for the variables in the data. This is a convenient way to have reasonable baselines for properties like `lower/upper`.\n",
    "\n",
    "Another common property is `n`, an estimate of the sample size of the data in question. In general, this could be based on true knowledge of the data, an educated guess, or we could produce it via a differentially private process. We know, by construction of the data set, that this is a 1,000 person sample.\n",
    "\n",
    "Yet another property is `nullity`, whether or not the validator can guarantee that results are not null. We will see what it looks like for both the `lower/upper` and `nullity` properties to change within an analysis. \n",
    "\n",
    "Let's start with `lower/upper`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original properties:\n",
      "array {\n",
      "  num_records {\n",
      "  }\n",
      "  num_columns {\n",
      "    option: 1\n",
      "  }\n",
      "  nullity: true\n",
      "  c_stability: 1\n",
      "  data_type: F64\n",
      "  dataset_id {\n",
      "    option: 1\n",
      "  }\n",
      "  is_not_empty: true\n",
      "  dimensionality {\n",
      "    option: 1\n",
      "  }\n",
      "  naturally_ordered: true\n",
      "  sample_proportion {\n",
      "  }\n",
      "  node_id: 4\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "properties after clamping:\n",
      "array {\n",
      "  num_records {\n",
      "  }\n",
      "  num_columns {\n",
      "    option: 1\n",
      "  }\n",
      "  nullity: true\n",
      "  c_stability: 1\n",
      "  data_type: F64\n",
      "  dataset_id {\n",
      "    option: 1\n",
      "  }\n",
      "  is_not_empty: true\n",
      "  dimensionality {\n",
      "    option: 1\n",
      "  }\n",
      "  naturally_ordered: true\n",
      "  sample_proportion {\n",
      "  }\n",
      "  node_id: 7\n",
      "  continuous {\n",
      "    minimum {\n",
      "      f64 {\n",
      "        data {\n",
      "          option: 0.0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    maximum {\n",
      "      f64 {\n",
      "        data {\n",
      "          option: 100.0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "properties after multiplication:\n",
      "array {\n",
      "  num_records {\n",
      "  }\n",
      "  num_columns {\n",
      "    option: 1\n",
      "  }\n",
      "  nullity: true\n",
      "  c_stability: 1\n",
      "  data_type: F64\n",
      "  dataset_id {\n",
      "    option: 1\n",
      "  }\n",
      "  is_not_empty: true\n",
      "  dimensionality {\n",
      "    option: 1\n",
      "  }\n",
      "  naturally_ordered: true\n",
      "  sample_proportion {\n",
      "  }\n",
      "  node_id: 9\n",
      "  continuous {\n",
      "    minimum {\n",
      "      f64 {\n",
      "        data {\n",
      "          option: 0.0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    maximum {\n",
      "      f64 {\n",
      "        data {\n",
      "          option: 200.0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with sn.Analysis() as analysis:\n",
    "    # load data\n",
    "    data = sn.Dataset(path = data_path, column_names = var_names)\n",
    "    \n",
    "    # establish data \n",
    "    age_dt = sn.to_float(data['age'])\n",
    "\n",
    "    # clamp data to set lower/upper properties\n",
    "    clamped_age_dt = sn.clamp(age_dt, lower = 0., upper = 100.)\n",
    "\n",
    "    # expand lower/upper by a factor of 2\n",
    "    clamped_age_dt_2 = sn.multiply(clamped_age_dt, 2.)\n",
    "\n",
    "\n",
    "analysis.release()\n",
    "print('original properties:\\n{0}\\n\\n'.format(age_dt.properties))\n",
    "print('properties after clamping:\\n{0}\\n\\n'.format(clamped_age_dt.properties))\n",
    "print('properties after multiplication:\\n{0}\\n\\n'.format(clamped_age_dt_2.properties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now move onto `nullity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original properties:\n",
      "array {\n",
      "  num_records {\n",
      "  }\n",
      "  num_columns {\n",
      "    option: 1\n",
      "  }\n",
      "  nullity: true\n",
      "  c_stability: 1\n",
      "  data_type: F64\n",
      "  dataset_id {\n",
      "    option: 1\n",
      "  }\n",
      "  is_not_empty: true\n",
      "  dimensionality {\n",
      "    option: 1\n",
      "  }\n",
      "  naturally_ordered: true\n",
      "  sample_proportion {\n",
      "  }\n",
      "  node_id: 4\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "properties after imputation:\n",
      "array {\n",
      "  num_records {\n",
      "  }\n",
      "  num_columns {\n",
      "    option: 1\n",
      "  }\n",
      "  c_stability: 1\n",
      "  data_type: F64\n",
      "  dataset_id {\n",
      "    option: 1\n",
      "  }\n",
      "  is_not_empty: true\n",
      "  dimensionality {\n",
      "    option: 1\n",
      "  }\n",
      "  naturally_ordered: true\n",
      "  sample_proportion {\n",
      "  }\n",
      "  node_id: 8\n",
      "  continuous {\n",
      "    minimum {\n",
      "      f64 {\n",
      "        data {\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    maximum {\n",
      "      f64 {\n",
      "        data {\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "properties after multiplication by nan:\n",
      "array {\n",
      "  num_records {\n",
      "  }\n",
      "  num_columns {\n",
      "    option: 1\n",
      "  }\n",
      "  nullity: true\n",
      "  c_stability: 1\n",
      "  data_type: F64\n",
      "  dataset_id {\n",
      "    option: 1\n",
      "  }\n",
      "  is_not_empty: true\n",
      "  dimensionality {\n",
      "    option: 1\n",
      "  }\n",
      "  naturally_ordered: true\n",
      "  sample_proportion {\n",
      "  }\n",
      "  node_id: 10\n",
      "  continuous {\n",
      "    minimum {\n",
      "      f64 {\n",
      "        data {\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    maximum {\n",
      "      f64 {\n",
      "        data {\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with sn.Analysis() as analysis:\n",
    "    # load data\n",
    "    data = sn.Dataset(path = data_path, column_names = var_names)\n",
    "    \n",
    "    # establish data \n",
    "    age_dt = sn.to_float(data['age'])\n",
    "\n",
    "    # ensure data are non-null \n",
    "    non_null_age_dt = sn.impute(age_dt, distribution = 'Uniform', lower = 0., upper = 100.)\n",
    "\n",
    "    # create null data\n",
    "    potentially_null_age_dt = sn.multiply(non_null_age_dt, float('nan'))\n",
    "\n",
    "analysis.release()\n",
    "print('original properties:\\n{0}\\n\\n'.format(age_dt.properties))\n",
    "print('properties after imputation:\\n{0}\\n\\n'.format(non_null_age_dt.properties))\n",
    "print('properties after multiplication by nan:\\n{0}\\n\\n'.format(potentially_null_age_dt.properties))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `nullity` property disappears after imputation (`nullity` disappearing is equivalent to `nullity: false`) and reappears after multiplication by `nan`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Now we can proceed to performing a basic analysis. Let's start by considering a differentially private mean of `age`. We will start with a few failed attempts in order to build an intuition for the requisite steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sample size\n",
    "n = 1_000\n",
    "\n",
    "# set ranges/feasible values\n",
    "age_range = (0., 100.)\n",
    "sex_vals = [0, 1]\n",
    "educ_vals = [i for i in range(1, 17)]\n",
    "race_vals = [i for i in range(1, 7)]\n",
    "income_range = (0., 500_000.)\n",
    "married_vals = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: at node_id 5\n",
      "Caused by: node specification SnappingMechanism(SnappingMechanism { privacy_usage: [PrivacyUsage { distance: Some(Approximate(DistanceApproximate { epsilon: 0.65, delta: 0.0 })) }] }):\n",
      "Caused by: node specification Mean(Mean):\n",
      "Caused by: Data may contain nullity when non-nullity is required. Use imputation to acquire this property.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/whitenoise/python/opendp/smartnoise/core/base.py:806: UserWarning: Some nodes were not allowed to execute.\n",
      "  warnings.warn(\"Some nodes were not allowed to execute.\")\n"
     ]
    }
   ],
   "source": [
    "# attempt 1 - fails because of nullity\n",
    "with sn.Analysis() as analysis:\n",
    "    # load data\n",
    "    data = sn.Dataset(path = data_path, column_names = var_names)\n",
    "    \n",
    "    ''' get mean age '''\n",
    "    # establish data \n",
    "    age_dt = sn.to_float(data['age'])\n",
    "    \n",
    "    # calculate differentially private mean of age\n",
    "    age_mean = sn.dp_mean(data = age_dt, privacy_usage={'epsilon': .65})\n",
    "\n",
    "analysis.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `dp_mean` requires the data to have the property `nullity = False`.\n",
    "We can get around this by using `impute`. We will impute from a `Gaussian(mean = 45, sd = 10)` distribution, truncated such that no values fall outside of our age range we already established."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: at node_id 11\n",
      "Caused by: node specification SnappingMechanism(SnappingMechanism { privacy_usage: [PrivacyUsage { distance: Some(Approximate(DistanceApproximate { epsilon: 0.65, delta: 0.0 })) }] }):\n",
      "Caused by: node specification Mean(Mean):\n",
      "Caused by: Lower bound(s) unknown. Use a clamp to set data bounds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# attempt 2 - fails because of undefined lower/upper\n",
    "with sn.Analysis() as analysis:\n",
    "    # load data\n",
    "    data = sn.Dataset(path = data_path, column_names = var_names)\n",
    "    \n",
    "    ''' get mean age '''\n",
    "    # establish data \n",
    "    age_dt = sn.to_float(data['age'])\n",
    "    \n",
    "    # impute missing values\n",
    "    age_dt = sn.impute(data = age_dt, distribution = 'Gaussian',\n",
    "                                      lower = age_range[0], upper = age_range[1],\n",
    "                                      shift = 45., scale = 10.)\n",
    "    \n",
    "    # calculate differentially private mean of age\n",
    "    age_mean = sn.dp_mean(data = age_dt, privacy_usage={'epsilon': .65})\n",
    "     \n",
    "analysis.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that `dp_mean` needs to know the `lower` value (in fact, it also needs to know `upper`). We provide that with `clamp`. We paramaterize `clamp` with the lower and upper values of age we established at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: at node_id 14\n",
      "Caused by: node specification SnappingMechanism(SnappingMechanism { privacy_usage: [PrivacyUsage { distance: Some(Approximate(DistanceApproximate { epsilon: 0.65, delta: 0.0 })) }] }):\n",
      "Caused by: node specification Mean(Mean):\n",
      "Caused by: Number of records is not defined. Use a data resize to acquire this property.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# attempt 3 - fails because of undefined n\n",
    "with sn.Analysis() as analysis:\n",
    "    # load data\n",
    "    data = sn.Dataset(path = data_path, column_names = var_names)\n",
    "    \n",
    "    ''' get mean age '''\n",
    "    # establish data \n",
    "    age_dt = sn.to_float(data['age'])\n",
    "    \n",
    "    # clamp data to range and impute missing values\n",
    "    age_dt = sn.clamp(data = age_dt, lower = age_range[0], upper = age_range[1])\n",
    "    age_dt = sn.impute(data = age_dt, distribution = 'Gaussian',\n",
    "                                      lower = age_range[0], upper = age_range[1],\n",
    "                                      shift = 45., scale = 10.)\n",
    "    \n",
    "    # calculate differentially private mean of age\n",
    "    age_mean = sn.dp_mean(data = age_dt, privacy_usage={'epsilon': .65})\n",
    "\n",
    "    \n",
    "analysis.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SmartNoise requires `n` to be specified before a mean release can be considered valid.\n",
    "We know the true `n` in this case, but this will not always be true. We call `resize` to ensure that the data are consistent with the `n` we provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.8\n",
      "410.0\n"
     ]
    }
   ],
   "source": [
    "# attempt 4 - succeeds!\n",
    "with sn.Analysis() as analysis:\n",
    "    # load data\n",
    "    data = sn.Dataset(path = data_path, column_names = var_names)\n",
    "    \n",
    "    ''' get mean age '''\n",
    "    # establish data \n",
    "    age_dt = sn.to_float(data['age'])\n",
    "    \n",
    "    # clamp data to range and impute missing values\n",
    "    age_dt = sn.clamp(data = age_dt, lower = age_range[0], upper = age_range[1])\n",
    "    age_dt = sn.impute(data = age_dt, distribution = 'Gaussian',\n",
    "                                      lower = age_range[0], upper = age_range[1],\n",
    "                                      shift = 45., scale = 10.)\n",
    "    \n",
    "    # ensure data are consistent with proposed n\n",
    "    age_dt = sn.resize(data = age_dt, number_rows = n, distribution = 'Gaussian',\n",
    "                       lower = age_range[0], upper = age_range[1],\n",
    "                       shift = 45., scale = 10.)\n",
    "    \n",
    "    # calculate differentially private mean of age\n",
    "    age_mean = sn.dp_mean(data = age_dt, privacy_usage={'epsilon': .65})\n",
    "        \n",
    "    ''' get variance of age '''\n",
    "    # calculate differentially private variance of age\n",
    "    age_var = sn.dp_variance(data = age_dt, privacy_usage={'epsilon': .35})\n",
    "    \n",
    "analysis.release()\n",
    "\n",
    "# print differentially private estimates of mean and variance of age\n",
    "print(age_mean.value)\n",
    "print(age_var.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we asked for an extra `dp_variance` at the end without having to use `clamp`, `impute`, or `resize`. Because these functions are updating the properties of `age_dt` as they are called, `dp_variance` has everything it needs from `age_dt` when we call it.\n",
    "\n",
    "Now that we have a sense for building up a statistic step-by-step, we can run through a much quicker version. We simply provide `data_lower, data_upper, data_rows` and the `clamp, impute, resize` steps are all performed implicitly. You'll notice that we don't even provide a `distribution` argument, even though it is needed for `impute`. For some arguments, we have (what we believe to be) reasonable defaults that are used if not provided explicitly.  For numerics, the default is to use a uniform distribution between the clamping min and max, but other distributions can be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP mean of age: 44.8\n",
      "DP variance of age: 290.0\n",
      "Privacy usage: approximate {\n",
      "  epsilon: 1.0\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with sn.Analysis() as analysis:\n",
    "    # load data\n",
    "    data = sn.Dataset(path = data_path, column_names = var_names)\n",
    "    \n",
    "    # cast to float\n",
    "    age_dt = sn.to_float(data['age'])\n",
    "    \n",
    "    # get mean of age\n",
    "    age_mean = sn.dp_mean(data = age_dt,\n",
    "                          privacy_usage = {'epsilon': .65},\n",
    "                          data_lower = 0.,\n",
    "                          data_upper = 100.,\n",
    "                          data_rows = 1000\n",
    "                         )\n",
    "    # get variance of age\n",
    "    age_var = sn.dp_variance(data = age_dt,\n",
    "                             privacy_usage = {'epsilon': .35},\n",
    "                             data_lower = 0.,\n",
    "                             data_upper = 100.,\n",
    "                             data_rows = 1000\n",
    "                            )\n",
    "analysis.release()\n",
    "\n",
    "print(\"DP mean of age: {0}\".format(age_mean.value))\n",
    "print(\"DP variance of age: {0}\".format(age_var.value))\n",
    "print(\"Privacy usage: {0}\".format(analysis.privacy_usage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the two DP releases within our analysis compose in a simple way, the individual epsilons we set add together for a total privacy usage of 1.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we have glossed over up until this point is the distinction between setting up and executing an analysis plan. An analysis plan is specified within the encapsulation of `sn.Analysis()` but until `analysis.release()` is run, the plan will not be validated and the data will not be touched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Release\n",
      "\n",
      "DP mean of age: 44.8\n",
      "Privacy usage: approximate {\n",
      "  epsilon: 0.65\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Post-Release\n",
      "\n",
      "DP mean of age: 44.8\n",
      "Privacy usage: approximate {\n",
      "  epsilon: 0.65\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with sn.Analysis() as analysis:\n",
    "    # load data\n",
    "    data = sn.Dataset(path = data_path, column_names = var_names)\n",
    "\n",
    "    # get mean of age\n",
    "    age_mean = sn.dp_mean(data = sn.to_float(data['age']),\n",
    "                          privacy_usage = {'epsilon': .65},\n",
    "                          data_lower = 0.,\n",
    "                          data_upper = 100.,\n",
    "                          data_rows = 1000\n",
    "                         )\n",
    "print(\"Pre-Release\\n\")\n",
    "print(\"DP mean of age: {0}\".format(age_mean.value))\n",
    "print(\"Privacy usage: {0}\\n\\n\".format(analysis.privacy_usage))\n",
    "\n",
    "analysis.release()\n",
    "\n",
    "print(\"Post-Release\\n\")\n",
    "print(\"DP mean of age: {0}\".format(age_mean.value))\n",
    "print(\"Privacy usage: {0}\\n\\n\".format(analysis.privacy_usage))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, a user will not know whether or not the validator will allow a proposed analysis until running `analysis.release()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' incomplete analysis plan, but no release => no failure '''\n",
    "with sn.Analysis() as analysis:\n",
    "    # load data\n",
    "    data = sn.Dataset(path = data_path, column_names = var_names)\n",
    "\n",
    "    age_mean_fail = sn.dp_mean(data = sn.to_float(data['age']),\n",
    "                          privacy_usage = {'epsilon': .65})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: at node_id 5\n",
      "Caused by: node specification SnappingMechanism(SnappingMechanism { privacy_usage: [PrivacyUsage { distance: Some(Approximate(DistanceApproximate { epsilon: 0.65, delta: 0.0 })) }] }):\n",
      "Caused by: node specification Mean(Mean):\n",
      "Caused by: Data may contain nullity when non-nullity is required. Use imputation to acquire this property.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' fails upon release '''\n",
    "analysis.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}